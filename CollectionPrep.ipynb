{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.probability import FreqDist\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morocco–Saudi Arabia relations\\n\\nMoroccan–Sau...</td>\n",
       "      <td>Morocco–Saudi_Arabia_relations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anthony United States Post Office\\n\\nThe Antho...</td>\n",
       "      <td>Anthony_United_States_Post_Office</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dumraon (Vidhan Sabha constituency)\\n\\nDumraon...</td>\n",
       "      <td>Dumraon__Vidhan_Sabha_constituency_</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chaker Khazaal\\n\\nChaker Khazaal (born 28 Sept...</td>\n",
       "      <td>Chaker_Khazaal</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vicente Pascual Pastor\\n\\nVicente Pascual Past...</td>\n",
       "      <td>Vicente_Pascual_Pastor</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Morocco–Saudi Arabia relations\\n\\nMoroccan–Sau...   \n",
       "1  Anthony United States Post Office\\n\\nThe Antho...   \n",
       "2  Dumraon (Vidhan Sabha constituency)\\n\\nDumraon...   \n",
       "3  Chaker Khazaal\\n\\nChaker Khazaal (born 28 Sept...   \n",
       "4  Vicente Pascual Pastor\\n\\nVicente Pascual Past...   \n",
       "\n",
       "                                 title  id  \n",
       "0       Morocco–Saudi_Arabia_relations   1  \n",
       "1    Anthony_United_States_Post_Office   2  \n",
       "2  Dumraon__Vidhan_Sabha_constituency_   3  \n",
       "3                       Chaker_Khazaal   4  \n",
       "4               Vicente_Pascual_Pastor   5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylist = []\n",
    "\n",
    "data = pd.read_csv('wikipedia_text_files.csv')\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morocco–Saudi Arabia relations\\n\\nMoroccan–Sau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anthony United States Post Office\\n\\nThe Antho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dumraon (Vidhan Sabha constituency)\\n\\nDumraon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chaker Khazaal\\n\\nChaker Khazaal (born 28 Sept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vicente Pascual Pastor\\n\\nVicente Pascual Past...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  Morocco–Saudi Arabia relations\\n\\nMoroccan–Sau...\n",
       "1  Anthony United States Post Office\\n\\nThe Antho...\n",
       "2  Dumraon (Vidhan Sabha constituency)\\n\\nDumraon...\n",
       "3  Chaker Khazaal\\n\\nChaker Khazaal (born 28 Sept...\n",
       "4  Vicente Pascual Pastor\\n\\nVicente Pascual Past..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = data[['content']]\n",
    "content[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ec87e769fff1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcontent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SentenceTokens'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3591\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m    105\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1275\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m         \"\"\"\n\u001b[1;32m-> 1277\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1329\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m         \"\"\"\n\u001b[1;32m-> 1331\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1329\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m         \"\"\"\n\u001b[1;32m-> 1331\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \"\"\"\n\u001b[0;32m   1361\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1362\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msl1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[1;34m(it)\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'after_tok'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "content['content'].fillna(\"\")\n",
    "content['SentenceTokens'] = content.content.apply(nltk.sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Documents</th>\n",
       "      <th>WordTokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Old-school musical numbers, feisty princesses,...</td>\n",
       "      <td>[Old-school, musical, numbers, ,, feisty, prin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anyone with an appreciation for old-school mus...</td>\n",
       "      <td>[Anyone, with, an, appreciation, for, old-scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frozen, the new animated film by Disney earns ...</td>\n",
       "      <td>[Frozen, ,, the, new, animated, film, by, Disn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The animation is simply superb. Ice has never ...</td>\n",
       "      <td>[The, animation, is, simply, superb, ., Ice, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An enjoyable fairy tale romp with some clever ...</td>\n",
       "      <td>[An, enjoyable, fairy, tale, romp, with, some,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Documents  \\\n",
       "0  Old-school musical numbers, feisty princesses,...   \n",
       "1  Anyone with an appreciation for old-school mus...   \n",
       "2  Frozen, the new animated film by Disney earns ...   \n",
       "3  The animation is simply superb. Ice has never ...   \n",
       "4  An enjoyable fairy tale romp with some clever ...   \n",
       "\n",
       "                                          WordTokens  \n",
       "0  [Old-school, musical, numbers, ,, feisty, prin...  \n",
       "1  [Anyone, with, an, appreciation, for, old-scho...  \n",
       "2  [Frozen, ,, the, new, animated, film, by, Disn...  \n",
       "3  [The, animation, is, simply, superb, ., Ice, h...  \n",
       "4  [An, enjoyable, fairy, tale, romp, with, some,...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words(\"english\")\n",
    "newStopWords = [',','.',':']\n",
    "sw.extend(newStopWords)\n",
    "df['NoStopwords'] = df.apply(lambda row: [w for w in row['WordTokens'] if not w in sw], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Documents</th>\n",
       "      <th>WordTokens</th>\n",
       "      <th>NoStopwords</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>Stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Old-school musical numbers, feisty princesses,...</td>\n",
       "      <td>[Old-school, musical, numbers, ,, feisty, prin...</td>\n",
       "      <td>[Old-school, musical, numbers, feisty, princes...</td>\n",
       "      <td>[old-school, musical, numbers, ,, feisty, prin...</td>\n",
       "      <td>[old-school, music, number, ,, feisti, princes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anyone with an appreciation for old-school mus...</td>\n",
       "      <td>[Anyone, with, an, appreciation, for, old-scho...</td>\n",
       "      <td>[Anyone, appreciation, old-school, musical, nu...</td>\n",
       "      <td>[anyone, appreciation, old-school, musical, nu...</td>\n",
       "      <td>[anyon, appreci, old-school, music, number, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frozen, the new animated film by Disney earns ...</td>\n",
       "      <td>[Frozen, ,, the, new, animated, film, by, Disn...</td>\n",
       "      <td>[Frozen, new, animated, film, Disney, earns, c...</td>\n",
       "      <td>[frozen, ,, new, animated, film, disney, earns...</td>\n",
       "      <td>[frozen, ,, new, anim, film, disney, earn, cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The animation is simply superb. Ice has never ...</td>\n",
       "      <td>[The, animation, is, simply, superb, ., Ice, h...</td>\n",
       "      <td>[The, animation, simply, superb, Ice, never, l...</td>\n",
       "      <td>[the, animation, simply, superb, ., ice, never...</td>\n",
       "      <td>[the, anim, simpli, superb, ., ice, never, loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An enjoyable fairy tale romp with some clever ...</td>\n",
       "      <td>[An, enjoyable, fairy, tale, romp, with, some,...</td>\n",
       "      <td>[An, enjoyable, fairy, tale, romp, clever, plo...</td>\n",
       "      <td>[an, enjoyable, fairy, tale, romp, clever, plo...</td>\n",
       "      <td>[an, enjoy, fairi, tale, romp, clever, plot, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Documents  \\\n",
       "0  Old-school musical numbers, feisty princesses,...   \n",
       "1  Anyone with an appreciation for old-school mus...   \n",
       "2  Frozen, the new animated film by Disney earns ...   \n",
       "3  The animation is simply superb. Ice has never ...   \n",
       "4  An enjoyable fairy tale romp with some clever ...   \n",
       "\n",
       "                                          WordTokens  \\\n",
       "0  [Old-school, musical, numbers, ,, feisty, prin...   \n",
       "1  [Anyone, with, an, appreciation, for, old-scho...   \n",
       "2  [Frozen, ,, the, new, animated, film, by, Disn...   \n",
       "3  [The, animation, is, simply, superb, ., Ice, h...   \n",
       "4  [An, enjoyable, fairy, tale, romp, with, some,...   \n",
       "\n",
       "                                         NoStopwords  \\\n",
       "0  [Old-school, musical, numbers, feisty, princes...   \n",
       "1  [Anyone, appreciation, old-school, musical, nu...   \n",
       "2  [Frozen, new, animated, film, Disney, earns, c...   \n",
       "3  [The, animation, simply, superb, Ice, never, l...   \n",
       "4  [An, enjoyable, fairy, tale, romp, clever, plo...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  [old-school, musical, numbers, ,, feisty, prin...   \n",
       "1  [anyone, appreciation, old-school, musical, nu...   \n",
       "2  [frozen, ,, new, animated, film, disney, earns...   \n",
       "3  [the, animation, simply, superb, ., ice, never...   \n",
       "4  [an, enjoyable, fairy, tale, romp, clever, plo...   \n",
       "\n",
       "                                             Stemmed  \n",
       "0  [old-school, music, number, ,, feisti, princes...  \n",
       "1  [anyon, appreci, old-school, music, number, fi...  \n",
       "2  [frozen, ,, new, anim, film, disney, earn, cha...  \n",
       "3  [the, anim, simpli, superb, ., ice, never, loo...  \n",
       "4  [an, enjoy, fairi, tale, romp, clever, plot, t...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Lowercase'] = [[w.lower() for w in wlst] for wlst in df['NoStopwords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Documents</th>\n",
       "      <th>WordTokens</th>\n",
       "      <th>NoStopwords</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>Stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Old-school musical numbers, feisty princesses,...</td>\n",
       "      <td>[Old-school, musical, numbers, ,, feisty, prin...</td>\n",
       "      <td>[Old-school, musical, numbers, feisty, princes...</td>\n",
       "      <td>[old-school, musical, numbers, feisty, princes...</td>\n",
       "      <td>[old-school, music, number, ,, feisti, princes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anyone with an appreciation for old-school mus...</td>\n",
       "      <td>[Anyone, with, an, appreciation, for, old-scho...</td>\n",
       "      <td>[Anyone, appreciation, old-school, musical, nu...</td>\n",
       "      <td>[anyone, appreciation, old-school, musical, nu...</td>\n",
       "      <td>[anyon, appreci, old-school, music, number, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frozen, the new animated film by Disney earns ...</td>\n",
       "      <td>[Frozen, ,, the, new, animated, film, by, Disn...</td>\n",
       "      <td>[Frozen, new, animated, film, Disney, earns, c...</td>\n",
       "      <td>[frozen, new, animated, film, disney, earns, c...</td>\n",
       "      <td>[frozen, ,, new, anim, film, disney, earn, cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The animation is simply superb. Ice has never ...</td>\n",
       "      <td>[The, animation, is, simply, superb, ., Ice, h...</td>\n",
       "      <td>[The, animation, simply, superb, Ice, never, l...</td>\n",
       "      <td>[the, animation, simply, superb, ice, never, l...</td>\n",
       "      <td>[the, anim, simpli, superb, ., ice, never, loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An enjoyable fairy tale romp with some clever ...</td>\n",
       "      <td>[An, enjoyable, fairy, tale, romp, with, some,...</td>\n",
       "      <td>[An, enjoyable, fairy, tale, romp, clever, plo...</td>\n",
       "      <td>[an, enjoyable, fairy, tale, romp, clever, plo...</td>\n",
       "      <td>[an, enjoy, fairi, tale, romp, clever, plot, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Documents  \\\n",
       "0  Old-school musical numbers, feisty princesses,...   \n",
       "1  Anyone with an appreciation for old-school mus...   \n",
       "2  Frozen, the new animated film by Disney earns ...   \n",
       "3  The animation is simply superb. Ice has never ...   \n",
       "4  An enjoyable fairy tale romp with some clever ...   \n",
       "\n",
       "                                          WordTokens  \\\n",
       "0  [Old-school, musical, numbers, ,, feisty, prin...   \n",
       "1  [Anyone, with, an, appreciation, for, old-scho...   \n",
       "2  [Frozen, ,, the, new, animated, film, by, Disn...   \n",
       "3  [The, animation, is, simply, superb, ., Ice, h...   \n",
       "4  [An, enjoyable, fairy, tale, romp, with, some,...   \n",
       "\n",
       "                                         NoStopwords  \\\n",
       "0  [Old-school, musical, numbers, feisty, princes...   \n",
       "1  [Anyone, appreciation, old-school, musical, nu...   \n",
       "2  [Frozen, new, animated, film, Disney, earns, c...   \n",
       "3  [The, animation, simply, superb, Ice, never, l...   \n",
       "4  [An, enjoyable, fairy, tale, romp, clever, plo...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  [old-school, musical, numbers, feisty, princes...   \n",
       "1  [anyone, appreciation, old-school, musical, nu...   \n",
       "2  [frozen, new, animated, film, disney, earns, c...   \n",
       "3  [the, animation, simply, superb, ice, never, l...   \n",
       "4  [an, enjoyable, fairy, tale, romp, clever, plo...   \n",
       "\n",
       "                                             Stemmed  \n",
       "0  [old-school, music, number, ,, feisti, princes...  \n",
       "1  [anyon, appreci, old-school, music, number, fi...  \n",
       "2  [frozen, ,, new, anim, film, disney, earn, cha...  \n",
       "3  [the, anim, simpli, superb, ., ice, never, loo...  \n",
       "4  [an, enjoy, fairi, tale, romp, clever, plot, t...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "df['Stemmed'] = [[ps.stem(w) for w in wlst] for wlst in df['Lowercase']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Documents</th>\n",
       "      <th>WordTokens</th>\n",
       "      <th>NoStopwords</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>Stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Old-school musical numbers, feisty princesses,...</td>\n",
       "      <td>[Old-school, musical, numbers, ,, feisty, prin...</td>\n",
       "      <td>[Old-school, musical, numbers, feisty, princes...</td>\n",
       "      <td>[old-school, musical, numbers, feisty, princes...</td>\n",
       "      <td>[old-school, music, number, feisti, princess, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anyone with an appreciation for old-school mus...</td>\n",
       "      <td>[Anyone, with, an, appreciation, for, old-scho...</td>\n",
       "      <td>[Anyone, appreciation, old-school, musical, nu...</td>\n",
       "      <td>[anyone, appreciation, old-school, musical, nu...</td>\n",
       "      <td>[anyon, appreci, old-school, music, number, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frozen, the new animated film by Disney earns ...</td>\n",
       "      <td>[Frozen, ,, the, new, animated, film, by, Disn...</td>\n",
       "      <td>[Frozen, new, animated, film, Disney, earns, c...</td>\n",
       "      <td>[frozen, new, animated, film, disney, earns, c...</td>\n",
       "      <td>[frozen, new, anim, film, disney, earn, charm,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The animation is simply superb. Ice has never ...</td>\n",
       "      <td>[The, animation, is, simply, superb, ., Ice, h...</td>\n",
       "      <td>[The, animation, simply, superb, Ice, never, l...</td>\n",
       "      <td>[the, animation, simply, superb, ice, never, l...</td>\n",
       "      <td>[the, anim, simpli, superb, ice, never, look, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An enjoyable fairy tale romp with some clever ...</td>\n",
       "      <td>[An, enjoyable, fairy, tale, romp, with, some,...</td>\n",
       "      <td>[An, enjoyable, fairy, tale, romp, clever, plo...</td>\n",
       "      <td>[an, enjoyable, fairy, tale, romp, clever, plo...</td>\n",
       "      <td>[an, enjoy, fairi, tale, romp, clever, plot, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Documents  \\\n",
       "0  Old-school musical numbers, feisty princesses,...   \n",
       "1  Anyone with an appreciation for old-school mus...   \n",
       "2  Frozen, the new animated film by Disney earns ...   \n",
       "3  The animation is simply superb. Ice has never ...   \n",
       "4  An enjoyable fairy tale romp with some clever ...   \n",
       "\n",
       "                                          WordTokens  \\\n",
       "0  [Old-school, musical, numbers, ,, feisty, prin...   \n",
       "1  [Anyone, with, an, appreciation, for, old-scho...   \n",
       "2  [Frozen, ,, the, new, animated, film, by, Disn...   \n",
       "3  [The, animation, is, simply, superb, ., Ice, h...   \n",
       "4  [An, enjoyable, fairy, tale, romp, with, some,...   \n",
       "\n",
       "                                         NoStopwords  \\\n",
       "0  [Old-school, musical, numbers, feisty, princes...   \n",
       "1  [Anyone, appreciation, old-school, musical, nu...   \n",
       "2  [Frozen, new, animated, film, Disney, earns, c...   \n",
       "3  [The, animation, simply, superb, Ice, never, l...   \n",
       "4  [An, enjoyable, fairy, tale, romp, clever, plo...   \n",
       "\n",
       "                                           Lowercase  \\\n",
       "0  [old-school, musical, numbers, feisty, princes...   \n",
       "1  [anyone, appreciation, old-school, musical, nu...   \n",
       "2  [frozen, new, animated, film, disney, earns, c...   \n",
       "3  [the, animation, simply, superb, ice, never, l...   \n",
       "4  [an, enjoyable, fairy, tale, romp, clever, plo...   \n",
       "\n",
       "                                             Stemmed  \n",
       "0  [old-school, music, number, feisti, princess, ...  \n",
       "1  [anyon, appreci, old-school, music, number, fi...  \n",
       "2  [frozen, new, anim, film, disney, earn, charm,...  \n",
       "3  [the, anim, simpli, superb, ice, never, look, ...  \n",
       "4  [an, enjoy, fairi, tale, romp, clever, plot, t...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "invertedIndex = {}\n",
    "for index, document in enumerate(df['Stemmed']):\n",
    "    for word in document:\n",
    "        if word in invertedIndex.keys():\n",
    "            invertedIndex[word].append(index)\n",
    "        else:\n",
    "            invertedIndex.update({word : [index]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'old-school': [0, 1],\n",
       " 'music': [0, 1],\n",
       " 'number': [0, 1],\n",
       " 'feisti': [0],\n",
       " 'princess': [0, 4],\n",
       " 'funni': [0],\n",
       " 'sidekick': [0],\n",
       " 'mix': [0],\n",
       " 'action': [0],\n",
       " 'comedi': [0],\n",
       " 'romanc': [0],\n",
       " 'come': [0],\n",
       " 'togeth': [0],\n",
       " 'frozen': [0, 1, 2, 3],\n",
       " 'disney': [0, 2, 4],\n",
       " 'anim': [0, 2, 3, 3],\n",
       " 'work': [0],\n",
       " 'hard': [0],\n",
       " 'keep': [0],\n",
       " 'everyon': [0],\n",
       " 'happi': [0],\n",
       " 'anyon': [1],\n",
       " 'appreci': [1],\n",
       " 'find': [1],\n",
       " 'someth': [1],\n",
       " 'pleasantli': [1],\n",
       " 'familiar': [1],\n",
       " 'cozi': [1],\n",
       " 'new': [2],\n",
       " 'film': [2],\n",
       " 'earn': [2],\n",
       " 'charm': [2],\n",
       " 'honest': [2],\n",
       " 'way': [2],\n",
       " 'smart': [2],\n",
       " 'write': [2],\n",
       " 'heartfelt': [2],\n",
       " 'perform': [2],\n",
       " 'the': [3],\n",
       " 'simpli': [3],\n",
       " 'superb': [3],\n",
       " 'ice': [3],\n",
       " 'never': [3],\n",
       " 'look': [3],\n",
       " 'good': [3],\n",
       " 'except': [3],\n",
       " 'real': [3],\n",
       " 'thing': [3],\n",
       " 'technic': [3],\n",
       " 'precis': [3],\n",
       " 'innov': [3],\n",
       " 'expect': [3],\n",
       " 'nowaday': [3],\n",
       " 'comput': [3],\n",
       " 'combin': [3],\n",
       " 'gorgeous': [3],\n",
       " 'rich': [3],\n",
       " 'design': [3],\n",
       " 'an': [4],\n",
       " 'enjoy': [4],\n",
       " 'fairi': [4],\n",
       " 'tale': [4],\n",
       " 'romp': [4],\n",
       " 'clever': [4],\n",
       " 'plot': [4],\n",
       " 'twist': [4],\n",
       " 'thrown': [4],\n",
       " 'posit': [4],\n",
       " 'messag': [4],\n",
       " 'young': [4],\n",
       " 'girl': [4],\n",
       " 'subvert': [4],\n",
       " 'usual': [4],\n",
       " 'provid': [4],\n",
       " 'tradit': [4]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invertedIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "print(len(invertedIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old-school\n",
      "music\n",
      "number\n",
      "feisti\n",
      "princess\n",
      "funni\n",
      "sidekick\n",
      "mix\n",
      "action\n",
      "comedi\n",
      "romanc\n",
      "come\n",
      "togeth\n",
      "frozen\n",
      "disney\n",
      "anim\n",
      "work\n",
      "hard\n",
      "keep\n",
      "everyon\n",
      "happi\n",
      "anyon\n",
      "appreci\n",
      "find\n",
      "someth\n",
      "pleasantli\n",
      "familiar\n",
      "cozi\n",
      "new\n",
      "film\n",
      "earn\n",
      "charm\n",
      "honest\n",
      "way\n",
      "smart\n",
      "write\n",
      "heartfelt\n",
      "perform\n",
      "the\n",
      "simpli\n",
      "superb\n",
      "ice\n",
      "never\n",
      "look\n",
      "good\n",
      "except\n",
      "real\n",
      "thing\n",
      "technic\n",
      "precis\n",
      "innov\n",
      "expect\n",
      "nowaday\n",
      "comput\n",
      "combin\n",
      "gorgeous\n",
      "rich\n",
      "design\n",
      "an\n",
      "enjoy\n",
      "fairi\n",
      "tale\n",
      "romp\n",
      "clever\n",
      "plot\n",
      "twist\n",
      "thrown\n",
      "posit\n",
      "messag\n",
      "young\n",
      "girl\n",
      "subvert\n",
      "usual\n",
      "provid\n",
      "tradit\n"
     ]
    }
   ],
   "source": [
    "for w in invertedIndex.keys():\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action [0]\n",
      "an [4]\n",
      "anim [0, 2, 3, 3]\n",
      "anyon [1]\n",
      "appreci [1]\n",
      "charm [2]\n",
      "clever [4]\n",
      "combin [3]\n",
      "come [0]\n",
      "comedi [0]\n",
      "comput [3]\n",
      "cozi [1]\n",
      "design [3]\n",
      "disney [0, 2, 4]\n",
      "earn [2]\n",
      "enjoy [4]\n",
      "everyon [0]\n",
      "except [3]\n",
      "expect [3]\n",
      "fairi [4]\n",
      "familiar [1]\n",
      "feisti [0]\n",
      "film [2]\n",
      "find [1]\n",
      "frozen [0, 1, 2, 3]\n",
      "funni [0]\n",
      "girl [4]\n",
      "good [3]\n",
      "gorgeous [3]\n",
      "happi [0]\n",
      "hard [0]\n",
      "heartfelt [2]\n",
      "honest [2]\n",
      "ice [3]\n",
      "innov [3]\n",
      "keep [0]\n",
      "look [3]\n",
      "messag [4]\n",
      "mix [0]\n",
      "music [0, 1]\n",
      "never [3]\n",
      "new [2]\n",
      "nowaday [3]\n",
      "number [0, 1]\n",
      "old-school [0, 1]\n",
      "perform [2]\n",
      "pleasantli [1]\n",
      "plot [4]\n",
      "posit [4]\n",
      "precis [3]\n",
      "princess [0, 4]\n",
      "provid [4]\n",
      "real [3]\n",
      "rich [3]\n",
      "romanc [0]\n",
      "romp [4]\n",
      "sidekick [0]\n",
      "simpli [3]\n",
      "smart [2]\n",
      "someth [1]\n",
      "subvert [4]\n",
      "superb [3]\n",
      "tale [4]\n",
      "technic [3]\n",
      "the [3]\n",
      "thing [3]\n",
      "thrown [4]\n",
      "togeth [0]\n",
      "tradit [4]\n",
      "twist [4]\n",
      "usual [4]\n",
      "way [2]\n",
      "work [0]\n",
      "write [2]\n",
      "young [4]\n"
     ]
    }
   ],
   "source": [
    "for key,value in sorted(invertedIndex.items()):\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "invertedIndexSorted = sorted(invertedIndex.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('action', [0]),\n",
       " ('an', [4]),\n",
       " ('anim', [0, 2, 3, 3]),\n",
       " ('anyon', [1]),\n",
       " ('appreci', [1]),\n",
       " ('charm', [2]),\n",
       " ('clever', [4]),\n",
       " ('combin', [3]),\n",
       " ('come', [0]),\n",
       " ('comedi', [0]),\n",
       " ('comput', [3]),\n",
       " ('cozi', [1]),\n",
       " ('design', [3]),\n",
       " ('disney', [0, 2, 4]),\n",
       " ('earn', [2]),\n",
       " ('enjoy', [4]),\n",
       " ('everyon', [0]),\n",
       " ('except', [3]),\n",
       " ('expect', [3]),\n",
       " ('fairi', [4]),\n",
       " ('familiar', [1]),\n",
       " ('feisti', [0]),\n",
       " ('film', [2]),\n",
       " ('find', [1]),\n",
       " ('frozen', [0, 1, 2, 3]),\n",
       " ('funni', [0]),\n",
       " ('girl', [4]),\n",
       " ('good', [3]),\n",
       " ('gorgeous', [3]),\n",
       " ('happi', [0]),\n",
       " ('hard', [0]),\n",
       " ('heartfelt', [2]),\n",
       " ('honest', [2]),\n",
       " ('ice', [3]),\n",
       " ('innov', [3]),\n",
       " ('keep', [0]),\n",
       " ('look', [3]),\n",
       " ('messag', [4]),\n",
       " ('mix', [0]),\n",
       " ('music', [0, 1]),\n",
       " ('never', [3]),\n",
       " ('new', [2]),\n",
       " ('nowaday', [3]),\n",
       " ('number', [0, 1]),\n",
       " ('old-school', [0, 1]),\n",
       " ('perform', [2]),\n",
       " ('pleasantli', [1]),\n",
       " ('plot', [4]),\n",
       " ('posit', [4]),\n",
       " ('precis', [3]),\n",
       " ('princess', [0, 4]),\n",
       " ('provid', [4]),\n",
       " ('real', [3]),\n",
       " ('rich', [3]),\n",
       " ('romanc', [0]),\n",
       " ('romp', [4]),\n",
       " ('sidekick', [0]),\n",
       " ('simpli', [3]),\n",
       " ('smart', [2]),\n",
       " ('someth', [1]),\n",
       " ('subvert', [4]),\n",
       " ('superb', [3]),\n",
       " ('tale', [4]),\n",
       " ('technic', [3]),\n",
       " ('the', [3]),\n",
       " ('thing', [3]),\n",
       " ('thrown', [4]),\n",
       " ('togeth', [0]),\n",
       " ('tradit', [4]),\n",
       " ('twist', [4]),\n",
       " ('usual', [4]),\n",
       " ('way', [2]),\n",
       " ('work', [0]),\n",
       " ('write', [2]),\n",
       " ('young', [4])]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invertedIndexSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
